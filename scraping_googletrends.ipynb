{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Web scraping for googletrends.com using the Python library Pytrends.**\n",
        "\n",
        "---\n",
        "\n",
        "üìé README\n",
        "\n",
        "This script executes code to scrape googletrends.com. It is necessary to input only the search terms and after save a CSV file with the name scraping_googletrends.csv."
      ],
      "metadata": {
        "id": "XvIHTeH2ZLqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 1. ‚ú® Installing dependences for Pytrends.\n",
        "\n",
        "!pip3 install pytrends &> /dev/null\n",
        "!pip install aiohttp &> /dev/null\n",
        "!pip install asyncio &> /dev/null\n",
        "\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import aiohttp\n",
        "import asyncio\n",
        "import time\n",
        "\n",
        "from pytrends.request import TrendReq\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vuOuUmb7Ztgf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. üí¨ Input the search terms and date.\n",
        "\n",
        "words_list = [\"facebook\"]\n",
        "\n",
        "start_date = datetime.date(2023, 12, 1)\n",
        "end_date = datetime.date(2023, 12, 2)"
      ],
      "metadata": {
        "id": "x8gidbCpaHQD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. ‚úç Run the script to scrape trends.google.com.\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "pytrends = TrendReq(hl='en-US', tz=360)\n",
        "#pytrends = TrendReq(hl='en-US', tz=360, timeout=(10,25), proxies=['https://34.203.233.13:80',], retries=2, backoff_factor=0.1, requests_args={'verify':False})\n",
        "\n",
        "data = []\n",
        "\n",
        "date_range = pd.date_range(start=start_date, end=end_date)\n",
        "\n",
        "def scraping_googletrends(kw_list,date_range):\n",
        "    for single_date in date_range:\n",
        "        formatted_date = single_date.strftime(\"%Y-%m-%d\")\n",
        "        pytrends.build_payload(kw_list, timeframe=f\"{formatted_date} {formatted_date}\")\n",
        "        interest_over_time_df = pytrends.interest_over_time()\n",
        "\n",
        "        if not interest_over_time_df.empty:\n",
        "            data.append(interest_over_time_df)\n",
        "    return data\n",
        "\n",
        "start = time.time()\n",
        "scraping_df = pd.concat(scraping_googletrends(words_list,date_range))\n",
        "\n",
        "scraping_df.to_csv('scraping_googletrends.csv')\n",
        "\n",
        "end = time.time()\n",
        "print('Task completed in: ',end - start,' seconds')\n",
        "\n",
        "scraping_df"
      ],
      "metadata": {
        "id": "UUl-y1mPa_hb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}